{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fc08e0ab-5bc9-4384-997f-2f8c87a5f1db",
   "metadata": {},
   "source": [
    "# Building GPT from scratch in code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d677dff6-e89a-465f-9140-39be51e107f5",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bb6ea1d-c6e8-4b25-8c76-f96cb8ce05e2",
   "metadata": {},
   "source": [
    "## overview"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44f1e5aa-529e-41f4-88da-96bb752e6df5",
   "metadata": {},
   "source": [
    "[reference video](https://www.youtube.com/watch?v=kCc8FmEb1nY)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37ff11cf-6f63-4adf-bf25-2a767a66ead3",
   "metadata": {},
   "source": [
    "### goal\n",
    "train a small scale GPT (generative pretrained transformer) to predict shakespeare-like text character by character."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1ed6cf1-3e80-4ba0-a7aa-8f78d984bf3b",
   "metadata": {},
   "source": [
    "### input dataset\n",
    "Tiny Shakespeare: 40k lines from a variety of Shakespeare plays"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "924a9b68-e948-4531-ad34-2a22bb2a7f04",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "37222e5f-b41b-4258-84ff-c3b7659a39d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2025-11-23 20:22:39--  https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.108.133, 185.199.111.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 1115394 (1.1M) [text/plain]\n",
      "Saving to: ‘input.txt.2’\n",
      "\n",
      "input.txt.2         100%[===================>]   1.06M  --.-KB/s    in 0.009s  \n",
      "\n",
      "2025-11-23 20:22:39 (113 MB/s) - ‘input.txt.2’ saved [1115394/1115394]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78b32f55-0a57-4e82-b897-c8d6fdeda34a",
   "metadata": {},
   "source": [
    "## getting familiar w the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a4861132-f563-4637-99a2-a9672f418067",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('input.txt', 'r', encoding='utf-8') as f:\n",
    "    text = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c88e17b2-dabb-4abc-9de3-1b5853d5422f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of dataset in characters 1115394\n"
     ]
    }
   ],
   "source": [
    "print(f'length of dataset in characters {len(text)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84f6032a-e8e0-4ec5-83ba-133162b481c9",
   "metadata": {},
   "source": [
    "### sample first 1000 characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7caff7f8-c5ac-4c1f-bb89-f167a401d3ed",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First Citizen:\n",
      "Before we proceed any further, hear me speak.\n",
      "\n",
      "All:\n",
      "Speak, speak.\n",
      "\n",
      "First Citizen:\n",
      "You are all resolved rather to die than to famish?\n",
      "\n",
      "All:\n",
      "Resolved. resolved.\n",
      "\n",
      "First Citizen:\n",
      "First, you know Caius Marcius is chief enemy to the people.\n",
      "\n",
      "All:\n",
      "We know't, we know't.\n",
      "\n",
      "First Citizen:\n",
      "Let us kill him, and we'll have corn at our own price.\n",
      "Is't a verdict?\n",
      "\n",
      "All:\n",
      "No more talking on't; let it be done: away, away!\n",
      "\n",
      "Second Citizen:\n",
      "One word, good citizens.\n",
      "\n",
      "First Citizen:\n",
      "We are accounted poor citizens, the patricians good.\n",
      "What authority surfeits on would relieve us: if they\n",
      "would yield us but the superfluity, while it were\n",
      "wholesome, we might guess they relieved us humanely;\n",
      "but they think we are too dear: the leanness that\n",
      "afflicts us, the object of our misery, is as an\n",
      "inventory to particularise their abundance; our\n",
      "sufferance is a gain to them Let us revenge this with\n",
      "our pikes, ere we become rakes: for the gods know I\n",
      "speak this in hunger for bread, not in thirst for revenge.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(text[0:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "04d4c9cd-a8ee-4abe-980e-b86b1d0a943d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " !$&',-.3:;?ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz\n",
      "vocab size: 65\n"
     ]
    }
   ],
   "source": [
    "chars = sorted(list(set(text)))\n",
    "vocab_size = len(chars)\n",
    "print(''.join(chars))\n",
    "print(f'vocab size: {vocab_size}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2bd02eb-10b0-42a8-86e8-af41828820b1",
   "metadata": {},
   "source": [
    "## Tokenizing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "197f21fc-d8f2-47be-bcc1-df7a28b02eaa",
   "metadata": {},
   "source": [
    "### construct a simple tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1d47f0c-6179-4e5b-ae84-85a18d420a08",
   "metadata": {},
   "source": [
    "nothing complicated here, just mapping each of the 65 unique characters to an int in 0 to 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d1b9802d-832e-4fee-8e77-ac7b82492237",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mapping of char -> index\n",
    "stoi = {ch:i for i,ch in enumerate(chars)}\n",
    "# also need a reverse mapping to translate gpt outputs into characters (decoder):\n",
    "itos = {i:ch for i,ch in enumerate(chars)}\n",
    "\n",
    "encode = lambda s: [stoi[c] for c in s] # encoder function: input a string of chars, output a list of integers (tokenized representation)\n",
    "decode = lambda l: ''.join([itos[i] for i in l]) # decoder function: input transformer output (list of tokens) into an english language string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b177882a-5eab-4c4b-9ca7-9e1a9de7f1d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[46, 43, 50, 50, 53]\n",
      "hello\n"
     ]
    }
   ],
   "source": [
    "print(encode('hello'))\n",
    "print(decode(encode('hello')))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15eea81b-5278-4b88-ab17-04dcc00a5891",
   "metadata": {},
   "source": [
    "### tokenize the entire training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7496a2b6-cd1b-4239-a803-cb8f69088e5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1388e58f-d30b-49ad-85a2-fb9d2d9ea2d5",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1115394]) torch.int64\n",
      "first 1000 characters tokenized: tensor([18, 47, 56, 57, 58,  1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 14, 43, 44,\n",
      "        53, 56, 43,  1, 61, 43,  1, 54, 56, 53, 41, 43, 43, 42,  1, 39, 52, 63,\n",
      "         1, 44, 59, 56, 58, 46, 43, 56,  6,  1, 46, 43, 39, 56,  1, 51, 43,  1,\n",
      "        57, 54, 43, 39, 49,  8,  0,  0, 13, 50, 50, 10,  0, 31, 54, 43, 39, 49,\n",
      "         6,  1, 57, 54, 43, 39, 49,  8,  0,  0, 18, 47, 56, 57, 58,  1, 15, 47,\n",
      "        58, 47, 64, 43, 52, 10,  0, 37, 53, 59,  1, 39, 56, 43,  1, 39, 50, 50,\n",
      "         1, 56, 43, 57, 53, 50, 60, 43, 42,  1, 56, 39, 58, 46, 43, 56,  1, 58,\n",
      "        53,  1, 42, 47, 43,  1, 58, 46, 39, 52,  1, 58, 53,  1, 44, 39, 51, 47,\n",
      "        57, 46, 12,  0,  0, 13, 50, 50, 10,  0, 30, 43, 57, 53, 50, 60, 43, 42,\n",
      "         8,  1, 56, 43, 57, 53, 50, 60, 43, 42,  8,  0,  0, 18, 47, 56, 57, 58,\n",
      "         1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 18, 47, 56, 57, 58,  6,  1, 63,\n",
      "        53, 59,  1, 49, 52, 53, 61,  1, 15, 39, 47, 59, 57,  1, 25, 39, 56, 41,\n",
      "        47, 59, 57,  1, 47, 57,  1, 41, 46, 47, 43, 44,  1, 43, 52, 43, 51, 63,\n",
      "         1, 58, 53,  1, 58, 46, 43,  1, 54, 43, 53, 54, 50, 43,  8,  0,  0, 13,\n",
      "        50, 50, 10,  0, 35, 43,  1, 49, 52, 53, 61,  5, 58,  6,  1, 61, 43,  1,\n",
      "        49, 52, 53, 61,  5, 58,  8,  0,  0, 18, 47, 56, 57, 58,  1, 15, 47, 58,\n",
      "        47, 64, 43, 52, 10,  0, 24, 43, 58,  1, 59, 57,  1, 49, 47, 50, 50,  1,\n",
      "        46, 47, 51,  6,  1, 39, 52, 42,  1, 61, 43,  5, 50, 50,  1, 46, 39, 60,\n",
      "        43,  1, 41, 53, 56, 52,  1, 39, 58,  1, 53, 59, 56,  1, 53, 61, 52,  1,\n",
      "        54, 56, 47, 41, 43,  8,  0, 21, 57,  5, 58,  1, 39,  1, 60, 43, 56, 42,\n",
      "        47, 41, 58, 12,  0,  0, 13, 50, 50, 10,  0, 26, 53,  1, 51, 53, 56, 43,\n",
      "         1, 58, 39, 50, 49, 47, 52, 45,  1, 53, 52,  5, 58, 11,  1, 50, 43, 58,\n",
      "         1, 47, 58,  1, 40, 43,  1, 42, 53, 52, 43, 10,  1, 39, 61, 39, 63,  6,\n",
      "         1, 39, 61, 39, 63,  2,  0,  0, 31, 43, 41, 53, 52, 42,  1, 15, 47, 58,\n",
      "        47, 64, 43, 52, 10,  0, 27, 52, 43,  1, 61, 53, 56, 42,  6,  1, 45, 53,\n",
      "        53, 42,  1, 41, 47, 58, 47, 64, 43, 52, 57,  8,  0,  0, 18, 47, 56, 57,\n",
      "        58,  1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 35, 43,  1, 39, 56, 43,  1,\n",
      "        39, 41, 41, 53, 59, 52, 58, 43, 42,  1, 54, 53, 53, 56,  1, 41, 47, 58,\n",
      "        47, 64, 43, 52, 57,  6,  1, 58, 46, 43,  1, 54, 39, 58, 56, 47, 41, 47,\n",
      "        39, 52, 57,  1, 45, 53, 53, 42,  8,  0, 35, 46, 39, 58,  1, 39, 59, 58,\n",
      "        46, 53, 56, 47, 58, 63,  1, 57, 59, 56, 44, 43, 47, 58, 57,  1, 53, 52,\n",
      "         1, 61, 53, 59, 50, 42,  1, 56, 43, 50, 47, 43, 60, 43,  1, 59, 57, 10,\n",
      "         1, 47, 44,  1, 58, 46, 43, 63,  0, 61, 53, 59, 50, 42,  1, 63, 47, 43,\n",
      "        50, 42,  1, 59, 57,  1, 40, 59, 58,  1, 58, 46, 43,  1, 57, 59, 54, 43,\n",
      "        56, 44, 50, 59, 47, 58, 63,  6,  1, 61, 46, 47, 50, 43,  1, 47, 58,  1,\n",
      "        61, 43, 56, 43,  0, 61, 46, 53, 50, 43, 57, 53, 51, 43,  6,  1, 61, 43,\n",
      "         1, 51, 47, 45, 46, 58,  1, 45, 59, 43, 57, 57,  1, 58, 46, 43, 63,  1,\n",
      "        56, 43, 50, 47, 43, 60, 43, 42,  1, 59, 57,  1, 46, 59, 51, 39, 52, 43,\n",
      "        50, 63, 11,  0, 40, 59, 58,  1, 58, 46, 43, 63,  1, 58, 46, 47, 52, 49,\n",
      "         1, 61, 43,  1, 39, 56, 43,  1, 58, 53, 53,  1, 42, 43, 39, 56, 10,  1,\n",
      "        58, 46, 43,  1, 50, 43, 39, 52, 52, 43, 57, 57,  1, 58, 46, 39, 58,  0,\n",
      "        39, 44, 44, 50, 47, 41, 58, 57,  1, 59, 57,  6,  1, 58, 46, 43,  1, 53,\n",
      "        40, 48, 43, 41, 58,  1, 53, 44,  1, 53, 59, 56,  1, 51, 47, 57, 43, 56,\n",
      "        63,  6,  1, 47, 57,  1, 39, 57,  1, 39, 52,  0, 47, 52, 60, 43, 52, 58,\n",
      "        53, 56, 63,  1, 58, 53,  1, 54, 39, 56, 58, 47, 41, 59, 50, 39, 56, 47,\n",
      "        57, 43,  1, 58, 46, 43, 47, 56,  1, 39, 40, 59, 52, 42, 39, 52, 41, 43,\n",
      "        11,  1, 53, 59, 56,  0, 57, 59, 44, 44, 43, 56, 39, 52, 41, 43,  1, 47,\n",
      "        57,  1, 39,  1, 45, 39, 47, 52,  1, 58, 53,  1, 58, 46, 43, 51,  1, 24,\n",
      "        43, 58,  1, 59, 57,  1, 56, 43, 60, 43, 52, 45, 43,  1, 58, 46, 47, 57,\n",
      "         1, 61, 47, 58, 46,  0, 53, 59, 56,  1, 54, 47, 49, 43, 57,  6,  1, 43,\n",
      "        56, 43,  1, 61, 43,  1, 40, 43, 41, 53, 51, 43,  1, 56, 39, 49, 43, 57,\n",
      "        10,  1, 44, 53, 56,  1, 58, 46, 43,  1, 45, 53, 42, 57,  1, 49, 52, 53,\n",
      "        61,  1, 21,  0, 57, 54, 43, 39, 49,  1, 58, 46, 47, 57,  1, 47, 52,  1,\n",
      "        46, 59, 52, 45, 43, 56,  1, 44, 53, 56,  1, 40, 56, 43, 39, 42,  6,  1,\n",
      "        52, 53, 58,  1, 47, 52,  1, 58, 46, 47, 56, 57, 58,  1, 44, 53, 56,  1,\n",
      "        56, 43, 60, 43, 52, 45, 43,  8,  0,  0])\n"
     ]
    }
   ],
   "source": [
    "data = torch.tensor(encode(text), dtype=torch.long)\n",
    "print(data.shape, data.dtype)\n",
    "print('first 1000 characters tokenized:', data[0:1000])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "470bbcd6-8c65-4bf9-bbf9-c031c8570e8d",
   "metadata": {},
   "source": [
    "## separate data into train/validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b8afc297-532f-4046-95a1-603314ae7873",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = int(0.9*len(data)) # truncate to a whole number bc index can only be an int\n",
    "\n",
    "train_data = data[0:n] # first 90% of data will be used to train\n",
    "val_data = data[n:] # remaining 10% will be held out for validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3249f95-404c-4ddb-8f5c-abb9f96d73c5",
   "metadata": {},
   "source": [
    "### generating x's and y's\n",
    "\n",
    "in supervised learning when it comes to categorization problems, there's a clear x input and y label. For example, in sentiment analysis u could have a movie review passage and a y label that indicates that the passage is positive or negative sentiment. In language generation, our training data isn't exactly labeled in this manner. We can fashion labels out of this by making each word itself the target y output and some of the words that precede the target word as the x. To get the transformer used to seeing different lengths of x, we can vary the context window from 1 to some block_size parameter. This allows us to also generate multiple training examples using one subset of the training dataset. You'll end up generating block_size examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bff40b91-b36e-4e29-82d5-fca91b420d42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([18, 47, 56, 57, 58,  1, 15, 47, 58])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "block_size = 8\n",
    "train_data[0:block_size+1] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c9e77dea-0ce0-40a9-86e7-1eb235c13200",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = train_data[0:block_size]\n",
    "y = train_data[1:block_size+1] # start @ 1 so that u predict the second word given 1st; +1 allows the 8th example to have a target y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8419a9c3-7547-4985-9713-341ac5470174",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "when input is tensor([18]) the target is 47\n",
      "when input is tensor([18, 47]) the target is 56\n",
      "when input is tensor([18, 47, 56]) the target is 57\n",
      "when input is tensor([18, 47, 56, 57]) the target is 58\n",
      "when input is tensor([18, 47, 56, 57, 58]) the target is 1\n",
      "when input is tensor([18, 47, 56, 57, 58,  1]) the target is 15\n",
      "when input is tensor([18, 47, 56, 57, 58,  1, 15]) the target is 47\n",
      "when input is tensor([18, 47, 56, 57, 58,  1, 15, 47]) the target is 58\n"
     ]
    }
   ],
   "source": [
    "for t in range(block_size): \n",
    "    context = x[0:t+1] # second index excluded\n",
    "    target = y[t] # y lists starts @ second character (see above cell)\n",
    "    print(f'when input is {context} the target is {target}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "535aaead-a975-4b53-9cd1-39e05ed79b55",
   "metadata": {},
   "source": [
    "### next we batch\n",
    "each block is like a training data snippet that we generate multiple training examples from. Then, we process multiple snippets at a time bc the gpu can do parallel processing (**batching**). this is different from multiple *epochs*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "80acf061-22ed-498b-a7ff-d1057c53d65f",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs:\n",
      "torch.Size([4, 8])\n",
      "tensor([[24, 43, 58,  5, 57,  1, 46, 43],\n",
      "        [44, 53, 56,  1, 58, 46, 39, 58],\n",
      "        [52, 58,  1, 58, 46, 39, 58,  1],\n",
      "        [25, 17, 27, 10,  0, 21,  1, 54]])\n",
      "targets:\n",
      "torch.Size([4, 8])\n",
      "tensor([[43, 58,  5, 57,  1, 46, 43, 39],\n",
      "        [53, 56,  1, 58, 46, 39, 58,  1],\n",
      "        [58,  1, 58, 46, 39, 58,  1, 46],\n",
      "        [17, 27, 10,  0, 21,  1, 54, 39]])\n",
      "----------------------------------------\n",
      "when input is 'L' the model should predict: 'e' as next char\n",
      "when input is 'Le' the model should predict: 't' as next char\n",
      "when input is 'Let' the model should predict: ''' as next char\n",
      "when input is 'Let'' the model should predict: 's' as next char\n",
      "when input is 'Let's' the model should predict: ' ' as next char\n",
      "when input is 'Let's ' the model should predict: 'h' as next char\n",
      "when input is 'Let's h' the model should predict: 'e' as next char\n",
      "when input is 'Let's he' the model should predict: 'a' as next char\n",
      "when input is 'f' the model should predict: 'o' as next char\n",
      "when input is 'fo' the model should predict: 'r' as next char\n",
      "when input is 'for' the model should predict: ' ' as next char\n",
      "when input is 'for ' the model should predict: 't' as next char\n",
      "when input is 'for t' the model should predict: 'h' as next char\n",
      "when input is 'for th' the model should predict: 'a' as next char\n",
      "when input is 'for tha' the model should predict: 't' as next char\n",
      "when input is 'for that' the model should predict: ' ' as next char\n",
      "when input is 'n' the model should predict: 't' as next char\n",
      "when input is 'nt' the model should predict: ' ' as next char\n",
      "when input is 'nt ' the model should predict: 't' as next char\n",
      "when input is 'nt t' the model should predict: 'h' as next char\n",
      "when input is 'nt th' the model should predict: 'a' as next char\n",
      "when input is 'nt tha' the model should predict: 't' as next char\n",
      "when input is 'nt that' the model should predict: ' ' as next char\n",
      "when input is 'nt that ' the model should predict: 'h' as next char\n",
      "when input is 'M' the model should predict: 'E' as next char\n",
      "when input is 'ME' the model should predict: 'O' as next char\n",
      "when input is 'MEO' the model should predict: ':' as next char\n",
      "when input is 'MEO:' the model should predict: '\n",
      "' as next char\n",
      "when input is 'MEO:\n",
      "' the model should predict: 'I' as next char\n",
      "when input is 'MEO:\n",
      "I' the model should predict: ' ' as next char\n",
      "when input is 'MEO:\n",
      "I ' the model should predict: 'p' as next char\n",
      "when input is 'MEO:\n",
      "I p' the model should predict: 'a' as next char\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(1337) # set random seed for reproducibility\n",
    "batch_size = 4 # how many snippets we process in parallel\n",
    "block_size = 8 # max length any x snippet can be (they'll range from 1 to block_size)\n",
    "\n",
    "def get_batch(split):\n",
    "    data = train_data if split == 'train' else val_data\n",
    "    idx = torch.randint(0, len(data)-block_size, (batch_size,)) # generate batch_size number of random indices to pull snippets from\n",
    "    x = torch.stack([data[i:i+block_size] for i in idx]) # torch.stack() takes in a list/tuple of tensors\n",
    "    y = torch.stack([data[i+1:i+block_size+1] for i in idx]) # e.g. for x = snippet[0] y = snippet[1], hence +1\n",
    "    return x,y\n",
    "\n",
    "\n",
    "\n",
    "xbatch, ybatch = get_batch('train')\n",
    "print('inputs:')\n",
    "print(xbatch.shape)\n",
    "print(xbatch)\n",
    "print('targets:')\n",
    "print(ybatch.shape)\n",
    "print(ybatch)\n",
    "\n",
    "print('-'*40)\n",
    "\n",
    "for b in range(batch_size):\n",
    "    for t in range(block_size): \n",
    "        context = xbatch[b, 0:t+1]\n",
    "        target = ybatch[b, t]\n",
    "        print(f'when input is \\'{decode(context.tolist())}\\' the model should predict: \\'{decode(target.unsqueeze(0).tolist())}\\' as next char')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0b72941-d8ff-4517-970d-f4e6c4afd290",
   "metadata": {},
   "source": [
    "## define the transformer model class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a499eb2e-a8e8-465f-91b7-e17b370dd789",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "torch.manual_seed(1337)\n",
    "\n",
    "class Transformer(nn.Module):\n",
    "    def __init__(self, vocab_size, emb_dim=20): # emb_dim is a hyperparameter, usually want this smaller than vocab_size\n",
    "        super().__init__()\n",
    "        self.token_embedding_table = nn.Embedding(vocab_size, emb_dim)\n",
    "\n",
    "    def forward(self, idx, targets=None):\n",
    "\n",
    "        if targets is None:\n",
    "            loss = None\n",
    "        else:\n",
    "            loss = F.cross_entropy(logits, targets)\n",
    "\n",
    "        return logits, loss\n",
    "\n",
    "    def generate(self, idx, max_new_tokens):\n",
    "        for _ in range(max_new_tokens):\n",
    "            logits, loss = self(idx)\n",
    "            logits = logits[:, -1, :] # u dont want what it predicts next token to be for the tokens u alr gave it in the prompt, u only want what it's newly generating\n",
    "            probs = F.softmax(logits, dim=-1) # last dim is probability dist over vocab size\n",
    "            idx_next = torch.multinomial(probs, num_samples=1) # sample the next char given the probability dist spit out by the model\n",
    "            idx = torch.cat((idx, idx_next), dim=1) # idx is (B, T) array of indices, use dim=1 to append to time dim\n",
    "        return idx    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0c0ce5b6-4d8a-443b-ac54-c30dc82c6fe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = Transformer(vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8e9d0eb3-0339-48dd-a2b5-d976de7d71cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.AdamW(m.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26ea10e6-39f0-4fd2-997e-308508a3b07c",
   "metadata": {},
   "outputs": [],
   "source": [
    "f"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "eval_harness",
   "language": "python",
   "name": "lmeh"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
